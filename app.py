import fitz
import re
import logging
import pandas as pd
from pathlib import Path
from datetime import datetime
import streamlit as st
import tempfile
from io import BytesIO
from github import Github
import base64
import requests

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.ERROR)
logger = logging.getLogger(__name__)
logger.setLevel(logging.ERROR)

# å®šä¹‰æŒ‰é¡µç åˆ†ç»„çš„æ­£åˆ™è¡¨è¾¾å¼
EXTRACTION_CONFIG = {
    1: [  
        r"(AMFSA00)\s+(\d+\.\d+)",  
        r"(MFSPD00)\s+(\d+\.\d+)",  
        r"(PUMFD00)\s+(\d+\.\d+)",  
        r"(MFRDD00)\s+(\d+\.\d+)",  
        r"(MFSAD00)\s+(\d+\.\d+)",  
        r"(MFHKD00)\s+(\d+\.\d+)",  
        r"(MFGBD00)\s+(\d+\.\d+)",  
        r"(MFZSD00)\s+\s*(\d+\.\d+)",  
        r"(MFFJD00)\s+(\d+\.\d+)",  
        r"(AMFFA00)\s+(\d+\.\d+)",  
        r"(MFNOD00)\s+(\d+\.\d+)",  
        r"(PPXDK00)\s+(\d+\.\d+)",  
        r"(MFSKD00)\s+(\d+\.\d+)",  
        r"(MFSHD00)\s+(\d+\.\d+)",  
    ],
    2: [                
        r"(AAXYP00)\s+\s*(\d+\.\d+)",    
        r"(PUAXP00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
    ],
    3: [
        r"(AAXYO00)\s+(\d+\.\d+)",  
        r"(BFDZA00)\s+\s*(\d+\.\d+)", 
        r"(MGZSD00)\s+\s*(\d+\.\d+)",
        r"(AAXYQ00)\s+\s*(\d+\.\d+)",
        r"(AAXYS00)\s+\s*(\d+\.\d+)",
        r"(AAXYR00)\s+\s*(\d+\.\d+)",
        r"(PUAFT00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",
        r"(AARKD00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",
        r"(PUAGQ00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",
        r"(PUAER00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",
        r"(PUAFN00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
        r"(AARTG00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
        r"(AAKAB00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
        r"(AARSU00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
    ],
    4: [  
        r"(AAGQE00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
        r"(AAWYA00)\s+\d+\.\d+â€“\d+\.\d+\s+(\d+\.\d+)",  
    ],
    5: [  
        r"(PUABC00)\s+\d+\.\d+-\d+\.\d+\s+(\d+\.\d+)",  
        r"(AAXWO00)\s+\s*(\d+\.\d+)",  
    ]
}
DATE_PATTERN = r"Volume\s+\d+\s+/\s+Issue\s+\d+\s+/\s+(\w+\s+\d{1,2},\s+\d{4})"

class PDFDataExtractor:
    def __init__(self, pdf_path: Path):
        self.pdf_path = pdf_path

    def extract_data(self) -> pd.DataFrame:
        doc = fitz.open(self.pdf_path)  
        extracted_data = {}  
        date = None  

        for page_num in range(len(doc)):  
            page = doc.load_page(page_num)  
            text = page.get_text().strip()  

            if page_num == 0:  
                date_match = re.search(DATE_PATTERN, text)
                if date_match:
                    date_str = date_match.group(1)
                    date = datetime.strptime(date_str, "%B %d, %Y").date()
                    extracted_data["Date"] = date

            patterns = EXTRACTION_CONFIG.get(page_num + 1, [])  
            for pattern in patterns:  
                matches = re.findall(pattern, text)
                for match in matches:  
                    code, value = match
                    extracted_data[code] = float(value)

        doc.close()  

        desired_order = [
            "Date",
            "AMFSA00", "MFSPD00", "PPXDK00", "PUAFT00", "AAXYO00", "PUMFD00", "MFRDD00", "PUABC00", "PUAFN00", "AARTG00",
            "MFSAD00", "AAXWO00", "MFZSD00", "BFDZA00", "MGZSD00", "MFHKD00", "PUAER00", "AAXYQ00", "MFSKD00",
            "PUAGQ00", "AAXYS00", "MFSHD00", "AARKD00", "AAXYR00", "MFGBD00", "AAKAB00", "AARSU00", "MFNOD00",
            "AAGQE00", "AAWYA00", "AMFFA00", "MFFJD00", "PUAXP00", "AAXYP00"
        ]
        sorted_data = {key: extracted_data.get(key) for key in desired_order}  
        return pd.DataFrame([sorted_data])  

class GitHubDataSaver:
    def __init__(self, repo_name: str, file_path: str, github_token: str):
        self.repo_name = repo_name
        self.file_path = file_path
        self.github_token = github_token

    def save_data(self, df: pd.DataFrame):
        if df.empty:
            return

        df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        current_date = df['Date'].iloc[0]

        try:
            # è¿æ¥åˆ°GitHub
            g = Github(self.github_token)
            repo = g.get_repo(self.repo_name)
            
            # å°è¯•è·å–ç°æœ‰æ–‡ä»¶
            try:
                contents = repo.get_contents(self.file_path)
                existing_data = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
                if current_date in existing_data['Date'].tolist():
                    st.warning(f"æ•°æ®æ—¥æœŸ {current_date} å·²å­˜åœ¨ï¼Œè·³è¿‡ä¿å­˜ã€‚")
                    return
                combined_df = pd.concat([existing_data, df])
            except Exception as e:
                # æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»ºæ–°æ–‡ä»¶
                combined_df = df

            # å¤„ç†æ•°æ®
            combined_df = combined_df.sort_values(by='Date', ascending=True)
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                combined_df.to_excel(writer, index=False)
            excel_data = output.getvalue()

            # æäº¤åˆ°GitHub
            if 'contents' in locals():
                repo.update_file(contents.path, f"æ›´æ–°æ•°æ® {datetime.today().date()}", excel_data, contents.sha)
            else:
                repo.create_file(self.file_path, "åˆå§‹æ•°æ®æäº¤", excel_data)
            
            st.success("æ•°æ®å·²ä¿å­˜åˆ°GitHubä»“åº“ï¼")
        except Exception as e:
            logger.error(f"ä¿å­˜å¤±è´¥: {str(e)}")
            st.error(f"ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {str(e)}")

def main_ui():
    st.set_page_config(page_title="PDF æ•°æ®æå–å™¨", layout="wide")
    st.title("PDF æ•°æ®æå–å™¨")

    # ä»Secretsè·å–GitHubé…ç½®
    try:
        github_token = st.secrets.github.token
        repo_name = st.secrets.github.repo
        file_path = "history_data/extracted_data.xlsx"
    except Exception as e:
        st.error("è¯·æ­£ç¡®é…ç½®GitHub Secretsï¼")
        return

    # æ–‡ä»¶ä¸Šä¼ æ¨¡å—
    with st.expander("ğŸ“¤ ç¬¬ä¸€æ­¥ - ä¸Šä¼ PDFæ–‡ä»¶", expanded=True):
        uploaded_file = st.file_uploader("é€‰æ‹©PDFæ–‡ä»¶", type=["pdf"])

    if uploaded_file:
        current_file_hash = hash(uploaded_file.getvalue())
        if 'last_file_hash' not in st.session_state or st.session_state.last_file_hash != current_file_hash:
            try:
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.getvalue())
                    pdf_path = Path(tmp.name)

                extractor = PDFDataExtractor(pdf_path)
                extracted_df = extractor.extract_data()

                saver = GitHubDataSaver(repo_name, file_path, github_token)
                saver.save_data(extracted_df)

                st.session_state.last_file_hash = current_file_hash
                st.success("æ•°æ®æå–æˆåŠŸï¼")
            except Exception as e:
                logger.error(f"å¤„ç†å¤±è´¥: {str(e)}")
                st.error(f"æ–‡ä»¶å¤„ç†é”™è¯¯: {str(e)}")

    # æ•°æ®å±•ç¤ºæ¨¡å—
    with st.expander("ğŸ“ˆ ç¬¬äºŒæ­¥ - æ•°æ®å±•ç¤º", expanded=True):
        try:
            # ä»GitHubè·å–æ•°æ®
            g = Github(github_token)
            repo = g.get_repo(repo_name)
            contents = repo.get_contents(file_path)
            data_df = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
            data_df['Date'] = pd.to_datetime(data_df['Date']).dt.strftime('%Y-%m-%d')
            data_df = data_df.sort_values(by='Date', ascending=False)
            st.subheader("æœ€è¿‘åæ¡è®°å½•")
            st.dataframe(data_df.head(10), use_container_width=True)
        except Exception as e:
            st.warning("æš‚æ— å†å²æ•°æ®æˆ–è¯»å–å¤±è´¥")

    # æ•°æ®å¯¼å‡ºæ¨¡å—ï¼ˆä¿æŒåŸæ ·ï¼Œä½†æ•°æ®æºæ”¹ä¸ºGitHubï¼‰
    with st.expander("ğŸ“¥ ç¬¬ä¸‰æ­¥ - æ•°æ®å¯¼å‡º", expanded=True):
        try:
            contents = repo.get_contents(file_path)
            data_df = pd.read_excel(BytesIO(base64.b64decode(contents.content)), engine='openpyxl')
            
            # æ–°å¢æ—¥æœŸå¤„ç†é€»è¾‘
            data_df['Date'] = pd.to_datetime(data_df['Date'])  # è½¬æ¢ä¸ºdatetimeç±»å‹
            data_df = data_df.sort_values('Date', ascending=False)  # æŒ‰æ—¥æœŸé™åºæ’åˆ—
            
            # ç”Ÿæˆæ’åºåçš„æ—¥æœŸé€‰é¡¹
            sorted_dates = data_df['Date'].dt.strftime('%Y-%m-%d').unique()
            
            st.subheader("æŒ‰æ—¥æœŸä¸‹è½½")
            selected_date = st.selectbox("é€‰æ‹©æ—¥æœŸ", options=sorted_dates)  # æ˜¾ç¤ºæ’åºåçš„æ—¥æœŸ
            
            daily_data = data_df[data_df['Date'] == pd.to_datetime(selected_date)]
            
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                daily_data.to_excel(writer, index=False)
            st.download_button(
                label="ä¸‹è½½é€‰å®šæ—¥æœŸæ•°æ®",
                data=output.getvalue(),
                file_name=f"data_{selected_date}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        except Exception as e:
            st.warning("æš‚æ— æ•°æ®å¯ä¾›å¯¼å‡º")

if __name__ == "__main__":
    main_ui()
